---
title: "Algoritmo de Metropolis-Hastings: ejemplo bidimensional"
output: html_document
---

```{r replicabilidad, include=FALSE}
set.seed(23059823)
```

Se pretende estimar \( \mathbb{E}_{f}[g(X_{1}, X_{2})] \), donde
\[
  f(x_{1}, x_{2}) \propto
  \begin{cases}
    \mathrm{e}^{-4 (x_{2} - x_{1}^{2})^{2} + (x_{2} - 1)^{2}}
    &\text{si } x_{2} \leq 2, \\
    0
    &\text{en otro caso.}
  \end{cases}
  \qquad
  g(x_{1}, x_2) = \sqrt{x_{1}^{2} + x_{2}^{2}}
\]

```{r densidad, message=FALSE}
library(plotly)

f_u <- function(x1, x2) {
  exp(-4 * (x2 - x1 ^ 2) ^ 2 + (x2 - 1) ^ 2) * (x2 <= 2)
}

# malla de puntos donde voy a representar la función
malla <- data.frame(x1 = (-250:250) / 100,
                    x2 = (-250:250) / 100)
plot_ly(malla, x = ~x2, y = ~x1) %>% 
    add_surface(z = outer(malla$x1, malla$x2, f_u) # outer: aplique la función en todas las combinaciones de la malla
                )
```

Tiene una zona donde acumula mayor probabilidad y dos picos donde hay menor probabilidad.


Vamos a realizar la estimación requerida a partir de un paseo aleatorio de Metropolis, haciendo uso del paquete `mcmc`. Para ello, en primer lugar debemos definir el logaritmo de la densidad objetivo como una función que toma como argumento un vector con los dos valores \( x_{1} \) y \( x_{2} \).

```{r log-densidad}
log_f_u <- function(x) { # función de un único argumento 
                         # (vector del estado, el vector (x1,x2))
  x1 <- x[1]
  x2 <- x[2]
  if (x2 <= 2) {
    -4 * (x2 - x1 ^ 2) ^ 2 + (x2 - 1) ^ 2
  } else {
    -Inf
  }
}
```

A continuación, iniciamos el paseo aleatorio de Metropolis a partir del estado \( x_{1} = x_{2} = 0 \), que según el gráfico se encuentra cerca de donde la densidad toma su máximo (donde acumula mayor probabilidad). Podemos comprobar que la función `metrop` devuelve la realización de la cadena de Markov en forma de matriz con dos columnas, ya que cada estado es una tupla de dos números reales.

Hemos tomado el inicial (0,0) porque en el gráfico vemos, mas o menos, que en el (0,0), nuestra curva acumula la mayor probabilidad. Hay que escoger un punto en la zona de probabilidad, aproximado.

```{r paseo-Metropolis}
paseo_Metropolis <- mcmc::metrop(log_f_u, initial = c(0, 0), nbatch = 1e4)
head(paseo_Metropolis$batch)
```

Rechazo el primero tres veces, luego acepto luego acepto y luego rechazo (en x1). Para x2, rechazo tres veces y luego acepto y vuelvo a rechazar dos veces.

La regla empírica establece que para acelerar la convergencia de la cadena de Markov a la densidad objetivo, el porcentaje de estados aceptados debería ser del 25 %.

```{r 25%-estados-aceptados}
paseo_Metropolis$accept # pordríamos admitir, está cerca del 25%
# Para acercarme al 25% de estados aceptados, disminuyo la varianza
paseo_Metropolis <- mcmc::metrop(paseo_Metropolis, scale = .9) 
# scale: controls the proposal step size
paseo_Metropolis$accept # me he pasado, voy a aumentar la varianza un poco para disminutir el porcentaje de estados aceptados
paseo_Metropolis <- mcmc::metrop(paseo_Metropolis, scale = .95)
paseo_Metropolis$accept
paseo_Metropolis <- mcmc::metrop(paseo_Metropolis, scale = .93)
paseo_Metropolis$accept
```


Como diagnóstico de convergencia, los siguientes gráficos parecen indicar que la cadena de Markov ha convergido a la densidad deseada.

```{r diagnóstico-convergencia}
library(coda)

traceplot(mcmc(paseo_Metropolis$batch))

library(ggplot2)

ggplot(expand.grid(x1 = (-250:250) / 100, x2 = (-250:250) / 100),
       aes(x = x1, y = x2, z = f_u(x1, x2))) +
  geom_contour() +
  geom_point(data = as.data.frame(paseo_Metropolis$batch),
             mapping = aes(x = V1, y = V2),
             size = .5,
             inherit.aes = FALSE)
```

Estamos ya en condiciones de obtener la estimación requerida, así como un intervalo de confianza para la misma. El gráfico de autocorrelación parece indicar que, al aplicar el método de las medias por lotes, la longitud de estos debería ser de al menos 50 estados.

```{r estimación}
autocorr.plot(mcmc(paseo_Metropolis$batch), lag.max = 100)

g <- function(x) {
  x1 <- x[1]
  x2 <- x[2]
  sqrt(x1 ^ 2 + x2 ^ 2)
}
paseo_Metropolis <- mcmc::metrop(paseo_Metropolis, nbatch = 1e3, blen = 1e2, outfun = g)
autocorr.plot(mcmc(paseo_Metropolis$batch))

valores <- as.vector(paseo_Metropolis$batch)
estimacion <- mean(valores)
error_estandar <- sqrt(var(valores) / paseo_Metropolis$nbatch)
probabilidad_cobertura <- 0.95
alfa <- 1 - probabilidad_cobertura
percentil <- qnorm(1 - alfa / 2)
intervalo_confianza <- estimacion + c(-1, 1) * error_estandar * percentil
```

Se obtiene entonces una estimación de `r estimacion`, con (`r intervalo_confianza`) un intervalo de confianza con probabilidad de cobertura `r probabilidad_cobertura`.
